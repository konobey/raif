{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Boosters] Raiffeisen Data Cup. Baseline\n",
    "Общий подход:\n",
    "- Добавляем к каждой транзакции столбец: is_work (если транзакция находится в пределах 0.02 от дома клиента)\n",
    "- Добавляем к каждой транзакции столбец: is_home (если транзакция находится в пределах 0.02 от работы клиента)\n",
    "- Обучаем классификатор предсказывающий вероятность (is_home == 1) для транзакции\n",
    "- Обучаем классификатор предсказывающий вероятность (is_work == 1) для транзакции\n",
    "\n",
    "Точность определения местоположения:\n",
    "- для классификатора is_home: ~3x%\n",
    "- для классификатора is_work: ~2x%\n",
    "- общая оценка на Public Leaderboard: ???\n",
    "\n",
    "Примечание\n",
    "* Требуется Python версии 3.5\n",
    "* Требуется библиотека xgboost (для обучения использовалась xgboost версии 0.7.post3)\n",
    "* Требуются файлы: test_set.csv, train_set.csv в одном каталоге с данным скриптом\n",
    "* Требования к памяти: должно работать с 2Гб свободного RAM\n",
    "* Время работы: ~3 минуты (тестировалось на процессоре Intel Core i7-4770)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "MODULES_PATH = '../code/'\n",
    "if MODULES_PATH not in sys.path:\n",
    "    sys.path.append(MODULES_PATH)\n",
    "import mfuncs\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_columns = 1000\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим типы колонок для экономии памяти\n",
    "dtypes = {\n",
    "    'transaction_date': str,\n",
    "    'atm_address': str,\n",
    "    'country': str,\n",
    "    'city': str,\n",
    "    'amount': np.float32,\n",
    "    'currency': np.float32,\n",
    "    'mcc': str,\n",
    "    'customer_id': str,\n",
    "    'pos_address': str,\n",
    "    'atm_address': str,\n",
    "    'pos_adress_lat': np.float32,\n",
    "    'pos_adress_lon': np.float32,\n",
    "    'pos_address_lat': np.float32,\n",
    "    'pos_address_lon': np.float32,\n",
    "    'atm_address_lat': np.float32,\n",
    "    'atm_address_lon': np.float32,\n",
    "    'home_add_lat': np.float32,\n",
    "    'home_add_lon': np.float32,\n",
    "    'work_add_lat': np.float32,\n",
    "    'work_add_lon': np.float32,\n",
    "}\n",
    "\n",
    "# для экономии памяти будем загружать только часть атрибутов транзакций\n",
    "usecols_train = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_adress_lat', 'pos_adress_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat','home_add_lon','work_add_lat','work_add_lon']\n",
    "usecols_test = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем train_set, test_set, соединяем в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'transaction_date': str,\n",
    "    'atm_address': str,\n",
    "    'country': str,\n",
    "    'city': str,\n",
    "    'amount': np.float32,\n",
    "    'currency': np.float32,\n",
    "    'mcc': str,\n",
    "    'customer_id': str,\n",
    "    'pos_address': str,\n",
    "    'atm_address': str,\n",
    "    'pos_adress_lat': np.float32,\n",
    "    'pos_adress_lon': np.float32,\n",
    "    'pos_address_lat': np.float32,\n",
    "    'pos_address_lon': np.float32,\n",
    "    'atm_address_lat': np.float32,\n",
    "    'atm_address_lon': np.float32,\n",
    "    'home_add_lat': np.float32,\n",
    "    'home_add_lon': np.float32,\n",
    "    'work_add_lat': np.float32,\n",
    "    'work_add_lon': np.float32,\n",
    "}\n",
    "\n",
    "rnm = {\n",
    "    'atm_address_lat': 'atm_lat',\n",
    "    'atm_address_lon': 'atm_lon',\n",
    "    'pos_adress_lat': 'pos_lat',\n",
    "    'pos_adress_lon': 'pos_lon',\n",
    "    'home_add_lat': 'home_lat',\n",
    "    'home_add_lon': 'home_lon',\n",
    "    'work_add_lat': 'work_lat',\n",
    "    'work_add_lon': 'work_lon',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train_set.csv', dtype=dtypes)\n",
    "df_test = pd.read_csv('../data/test_set.csv', dtype=dtypes)\n",
    "\n",
    "df_train.rename(columns=rnm, inplace=True)\n",
    "df_test.rename(columns=rnm, inplace=True)\n",
    "\n",
    "# соединяем test/train в одном DataFrame\n",
    "df_train['is_train'] = np.int32(1)\n",
    "df_test['is_train'] = np.int32(0)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "del df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обрабатываем дату транзакции и категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['currency'] = df_all['currency'].fillna(-1).astype(np.int32)\n",
    "df_all['mcc'] = df_all['mcc'].apply(lambda x: int(x.replace(',', ''))).astype(np.int32)\n",
    "df_all['city'] = df_all['city'].factorize()[0].astype(np.int32)\n",
    "df_all['country'] = df_all['country'].factorize()[0].astype(np.int32)\n",
    "\n",
    "# удаляем транзакции без даты\n",
    "df_all = df_all[~df_all['transaction_date'].isnull()]\n",
    "df_all['transaction_date'] =  pd.to_datetime(df_all['transaction_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи для даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['month'] = df_all.transaction_date.dt.month\n",
    "df_all['day'] = df_all.transaction_date.dt.day\n",
    "df_all['dayofyear'] = df_all.transaction_date.dt.dayofyear\n",
    "df_all['dayofweek'] = df_all.transaction_date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приводим адрес транзакции для pos и atm-транзакций к единообразному виду\n",
    "Просто объединяем в одну колонку и добавляем фичу - это атм или пос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['is_atm'] = (~df_all['atm_lat'].isnull()).astype(np.int8)\n",
    "df_all['is_pos'] = (~df_all['pos_lat'].isnull()).astype(np.int8)\n",
    "\n",
    "df_all['add_lat'] = df_all['atm_lat'].fillna(0) + df_all['pos_lat'].fillna(0)\n",
    "df_all['add_lon'] = df_all['atm_lon'].fillna(0) + df_all['pos_lon'].fillna(0)\n",
    "\n",
    "df_all.drop(['atm_lat','atm_lon','pos_lat','pos_lon'], axis=1, inplace=True)\n",
    "\n",
    "df_all = df_all[~((df_all['add_lon'] == 0) & (df_all['add_lon'] == 0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем признаки is_home, is_work\n",
    "TODO: удалить чуваков у которых несколько домов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = df_all['home_lat'] - df_all['add_lat']\n",
    "lon = df_all['home_lon'] - df_all['add_lon']\n",
    "\n",
    "df_all['is_home'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int8)\n",
    "df_all['has_home'] = (~df_all['home_lon'].isnull()).astype(np.int8)\n",
    "\n",
    "lat = df_all['work_lat'] - df_all['add_lat']\n",
    "lon = df_all['work_lon'] - df_all['add_lon']\n",
    "df_all['is_work'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int8)\n",
    "df_all['has_work'] = (~df_all['work_lon'].isnull()).astype(np.int8)\n",
    "\n",
    "df_all.drop(['work_lat','work_lon','home_lat','home_lon'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем категориальный признак для адреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['address'] = df_all['add_lat'].apply(lambda x: \"%.02f\" % x) + ';' + df_all['add_lon'].apply(lambda x: \"%.02f\" % x)\n",
    "df_all['address'] = df_all['address'].factorize()[0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем несколько абонентских фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество транзакций каждого клиента\n",
    "df_all = df_all.merge(df_all.groupby('customer_id')['amount'].count().reset_index(name='cid_trans_count'), how='left')\n",
    "df_all['cid_trans_count'] = df_all['cid_trans_count'].astype(np.int32)\n",
    "\n",
    "df_all = df_all.merge(df_all.groupby(['customer_id','address'])['amount'].count().reset_index(name='cid_add_trans_count'), \n",
    "                      how='left')\n",
    "df_all['cid_add_trans_count'] = df_all['cid_add_trans_count'].astype(np.int32)\n",
    "\n",
    "# какая часть транзакций клиента приходится на данный адрес\n",
    "# TODO: БОЛЬШЕ ТАКИХ ФИЧ\n",
    "df_all['ratio1'] = df_all['cid_add_trans_count'] / df_all['cid_trans_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции для оценки точности классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>atm_address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>currency</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>is_train</th>\n",
       "      <th>mcc</th>\n",
       "      <th>pos_address</th>\n",
       "      <th>pos_address_lat</th>\n",
       "      <th>pos_address_lon</th>\n",
       "      <th>terminal_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_atm</th>\n",
       "      <th>is_pos</th>\n",
       "      <th>add_lat</th>\n",
       "      <th>add_lon</th>\n",
       "      <th>is_home</th>\n",
       "      <th>has_home</th>\n",
       "      <th>is_work</th>\n",
       "      <th>has_work</th>\n",
       "      <th>address</th>\n",
       "      <th>cid_trans_count</th>\n",
       "      <th>cid_add_trans_count</th>\n",
       "      <th>ratio1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.884034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11606fde0c814ce78e0d726e39a0a5ee</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>196</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.844074</td>\n",
       "      <td>30.179153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.775633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e9647a5e1eacfb06713b6af755ccc595</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.844074</td>\n",
       "      <td>30.179153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.708368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5992</td>\n",
       "      <td>PR.MARSHALA ZHUKOVA,31St Petersburg190000    7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>df06c1fcd3718a514535ae822785f716</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.858200</td>\n",
       "      <td>30.229023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.787498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6c5e5793ebc984fb72875feffff62854</td>\n",
       "      <td>2017-09-09</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>252</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.844074</td>\n",
       "      <td>30.179153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.892510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0576445d74e374c92c0902e612fca356</td>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>187</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.844074</td>\n",
       "      <td>30.179153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount atm_address  city  country  currency  \\\n",
       "0  2.884034         NaN     0        0       643   \n",
       "1  2.775633         NaN     0        0       643   \n",
       "2  3.708368         NaN     1        0       643   \n",
       "3  2.787498         NaN     0        0       643   \n",
       "4  2.892510         NaN     0        0       643   \n",
       "\n",
       "                        customer_id  is_train   mcc  \\\n",
       "0  0dc0137d280a2a82d2dc89282450ff1b         1  5261   \n",
       "1  0dc0137d280a2a82d2dc89282450ff1b         1  5261   \n",
       "2  0dc0137d280a2a82d2dc89282450ff1b         1  5992   \n",
       "3  0dc0137d280a2a82d2dc89282450ff1b         1  5261   \n",
       "4  0dc0137d280a2a82d2dc89282450ff1b         1  5261   \n",
       "\n",
       "                                         pos_address  pos_address_lat  \\\n",
       "0                                                NaN              NaN   \n",
       "1                                                NaN              NaN   \n",
       "2  PR.MARSHALA ZHUKOVA,31St Petersburg190000    7...              NaN   \n",
       "3                                                NaN              NaN   \n",
       "4                                                NaN              NaN   \n",
       "\n",
       "   pos_address_lon                       terminal_id transaction_date  month  \\\n",
       "0              NaN  11606fde0c814ce78e0d726e39a0a5ee       2017-07-15      7   \n",
       "1              NaN  e9647a5e1eacfb06713b6af755ccc595       2017-10-27     10   \n",
       "2              NaN  df06c1fcd3718a514535ae822785f716       2017-10-03     10   \n",
       "3              NaN  6c5e5793ebc984fb72875feffff62854       2017-09-09      9   \n",
       "4              NaN  0576445d74e374c92c0902e612fca356       2017-07-06      7   \n",
       "\n",
       "   day  dayofyear  dayofweek  is_atm  is_pos    add_lat    add_lon  is_home  \\\n",
       "0   15        196          5       0       1  59.844074  30.179153        0   \n",
       "1   27        300          4       0       1  59.844074  30.179153        0   \n",
       "2    3        276          1       0       1  59.858200  30.229023        1   \n",
       "3    9        252          5       0       1  59.844074  30.179153        0   \n",
       "4    6        187          3       0       1  59.844074  30.179153        0   \n",
       "\n",
       "   has_home  is_work  has_work  address  cid_trans_count  cid_add_trans_count  \\\n",
       "0         1        1         1        0               70                   23   \n",
       "1         1        1         1        0               70                   23   \n",
       "2         1        0         1        1               70                   10   \n",
       "3         1        1         1        0               70                   23   \n",
       "4         1        1         1        0               70                   23   \n",
       "\n",
       "     ratio1  \n",
       "0  0.328571  \n",
       "1  0.328571  \n",
       "2  0.142857  \n",
       "3  0.328571  \n",
       "4  0.328571  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ys = ['is_home', 'is_work']\n",
    "drop_cols = ['atm_address', 'customer_id', 'pos_address', 'terminal_id', 'transaction_date', \n",
    "             'is_home' ,'has_home', 'is_work', 'has_work', 'is_train']\n",
    "\n",
    "\n",
    "drop_cols += ['pred:is_home', 'pred:is_work']\n",
    "\n",
    "\n",
    "y_cols = ['is_home', 'is_work']\n",
    "cust_train = df_all[df_all['is_train']==1].groupby('customer_id')[y_col.replace('is_','has_')].max()\n",
    "cust_train = cust_train[cust_train > 0].index\n",
    "\n",
    "cust_train, cust_valid = train_test_split(cust_train, test_size=0.2, shuffle=True, random_state=111)\n",
    "\n",
    "# df_train = df_all[df_all.customer_id.isin(cust_train)]\n",
    "# df_valid = df_all[df_all.customer_id.isin(cust_valid)]\n",
    "\n",
    "df_train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(df_all, how='left')\n",
    "df_valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(df_all, how='left')\n",
    "\n",
    "usecols = df_train.drop(drop_cols, 1, errors='ignore').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'metric' : 'binary_logloss',\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'num_threads': 12,\n",
    "    'verbose': 0,\n",
    "}\n",
    "\n",
    "model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[30]\tvalid_0's binary_logloss: 0.485937\n",
      "[60]\tvalid_0's binary_logloss: 0.459724\n",
      "[90]\tvalid_0's binary_logloss: 0.4526\n",
      "[120]\tvalid_0's binary_logloss: 0.451434\n",
      "[150]\tvalid_0's binary_logloss: 0.452001\n",
      "[180]\tvalid_0's binary_logloss: 0.45209\n",
      "[210]\tvalid_0's binary_logloss: 0.451627\n",
      "[240]\tvalid_0's binary_logloss: 0.452041\n",
      "[270]\tvalid_0's binary_logloss: 0.451442\n",
      "[300]\tvalid_0's binary_logloss: 0.452191\n",
      "[330]\tvalid_0's binary_logloss: 0.451919\n",
      "[360]\tvalid_0's binary_logloss: 0.452594\n",
      "[390]\tvalid_0's binary_logloss: 0.452038\n",
      "[420]\tvalid_0's binary_logloss: 0.452356\n",
      "[450]\tvalid_0's binary_logloss: 0.452787\n",
      "[480]\tvalid_0's binary_logloss: 0.452926\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.450945\n"
     ]
    }
   ],
   "source": [
    "y_col = 'is_home'\n",
    "\n",
    "lgb_train = lgb.Dataset(df_train[usecols], df_train[y_col])\n",
    "lgb_valid = lgb.Dataset(df_valid[usecols], df_valid[y_col])\n",
    "\n",
    "gbm_h = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets=[lgb_valid],\n",
    "                num_boost_round=2000,\n",
    "                verbose_eval=30,\n",
    "                early_stopping_rounds=300)\n",
    "\n",
    "model[y_col] = gbm_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[30]\tvalid_0's binary_logloss: 0.330132\n",
      "[60]\tvalid_0's binary_logloss: 0.285479\n",
      "[90]\tvalid_0's binary_logloss: 0.277591\n",
      "[120]\tvalid_0's binary_logloss: 0.275894\n",
      "[150]\tvalid_0's binary_logloss: 0.276834\n",
      "[180]\tvalid_0's binary_logloss: 0.277931\n",
      "[210]\tvalid_0's binary_logloss: 0.278973\n",
      "[240]\tvalid_0's binary_logloss: 0.280465\n",
      "[270]\tvalid_0's binary_logloss: 0.281767\n",
      "[300]\tvalid_0's binary_logloss: 0.283068\n",
      "[330]\tvalid_0's binary_logloss: 0.283879\n",
      "[360]\tvalid_0's binary_logloss: 0.286295\n",
      "[390]\tvalid_0's binary_logloss: 0.287128\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.275737\n"
     ]
    }
   ],
   "source": [
    "y_col = 'is_work'\n",
    "\n",
    "lgb_train = lgb.Dataset(df_train[usecols], df_train[y_col])\n",
    "lgb_valid = lgb.Dataset(df_valid[usecols], df_valid[y_col])\n",
    "\n",
    "gbm_w = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets=[lgb_valid],\n",
    "                num_boost_round=2000,\n",
    "                verbose_eval=30,\n",
    "                early_stopping_rounds=300)\n",
    "\n",
    "model[y_col] = gbm_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _best(x):\n",
    "    ret = None\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        if pred in x:\n",
    "            i = (x[pred].idxmax())\n",
    "            cols = [pred, 'add_lat', 'add_lon']\n",
    "            if col in x:\n",
    "                cols.append(col)\n",
    "            tmp = x.loc[i,cols]\n",
    "            tmp.rename({\n",
    "                'add_lat':'%s:add_lat' % col,\n",
    "                'add_lon':'%s:add_lon' % col,\n",
    "            }, inplace = True)\n",
    "            if ret is None:\n",
    "                ret = tmp\n",
    "            else:\n",
    "                ret = pd.concat([ret, tmp])\n",
    "    return ret\n",
    "\n",
    "def predict_proba(dt, ys=['is_home', 'is_work']):\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        dt[pred] = model[col].predict(dt[usecols])\n",
    "    return dt.groupby('customer_id').apply(_best).reset_index()\n",
    "\n",
    "def score(dt, ys=['is_home', 'is_work']):\n",
    "    dt_ret = predict_proba(dt, ys)\n",
    "    mean = 0.0\n",
    "    for col in ys:\n",
    "        col_mean = dt_ret[col].mean()\n",
    "        mean += col_mean\n",
    "    if len(ys) == 2:\n",
    "        mean = mean / len(ys)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.440375\n",
      "Test accuracy: 0.396\n",
      "Train accuracy: 0.16875\n",
      "Test accuracy: 0.1495\n"
     ]
    }
   ],
   "source": [
    "print (\"Train accuracy:\", score(df_train, ys=['is_home']))\n",
    "print (\"Test accuracy:\", score(df_valid, ys=['is_home']))\n",
    "\n",
    "print (\"Train accuracy:\", score(df_train, ys=['is_work']))\n",
    "print (\"Test accuracy:\", score(df_valid, ys=['is_work']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_ID_</th>\n",
       "      <th>_WORK_LAT_</th>\n",
       "      <th>_WORK_LON_</th>\n",
       "      <th>_HOME_LAT_</th>\n",
       "      <th>_HOME_LON_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00021683ccb416637fe9a4cd35e4606e</td>\n",
       "      <td>55.026001</td>\n",
       "      <td>82.915001</td>\n",
       "      <td>55.027000</td>\n",
       "      <td>82.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002d0f8a642272b41c292c12ab6e602</td>\n",
       "      <td>44.034000</td>\n",
       "      <td>42.835999</td>\n",
       "      <td>44.032001</td>\n",
       "      <td>42.837002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d182d9fede3ba2534b2d5e5ad27e</td>\n",
       "      <td>43.591000</td>\n",
       "      <td>39.724998</td>\n",
       "      <td>43.584999</td>\n",
       "      <td>39.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0008c2445518c9392cb356c5c3db3392</td>\n",
       "      <td>51.526001</td>\n",
       "      <td>46.019001</td>\n",
       "      <td>51.526001</td>\n",
       "      <td>46.019001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001611e3ac051a0ec91c88bbd9dbeb5a</td>\n",
       "      <td>56.998001</td>\n",
       "      <td>40.959000</td>\n",
       "      <td>57.001999</td>\n",
       "      <td>40.963001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               _ID_  _WORK_LAT_  _WORK_LON_  _HOME_LAT_  \\\n",
       "0  00021683ccb416637fe9a4cd35e4606e   55.026001   82.915001   55.027000   \n",
       "1  0002d0f8a642272b41c292c12ab6e602   44.034000   42.835999   44.032001   \n",
       "2  0004d182d9fede3ba2534b2d5e5ad27e   43.591000   39.724998   43.584999   \n",
       "3  0008c2445518c9392cb356c5c3db3392   51.526001   46.019001   51.526001   \n",
       "4  001611e3ac051a0ec91c88bbd9dbeb5a   56.998001   40.959000   57.001999   \n",
       "\n",
       "   _HOME_LON_  \n",
       "0   82.917000  \n",
       "1   42.837002  \n",
       "2   39.723000  \n",
       "3   46.019001  \n",
       "4   40.963001  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_test = df_all[df_all['is_train'] == 0]['customer_id'].unique()\n",
    "df_test = pd.DataFrame(cust_test, columns = ['customer_id']).merge(df_all, how = 'left')\n",
    "df_test = predict_proba(df_test)\n",
    "df_test.rename(columns = {\n",
    "        'customer_id':'_ID_',\n",
    "        'is_home:add_lat': '_HOME_LAT_',\n",
    "        'is_home:add_lon': '_HOME_LON_',\n",
    "        'is_work:add_lat': '_WORK_LAT_',\n",
    "        'is_work:add_lon': '_WORK_LON_'}, inplace = True)\n",
    "df_test = df_test[['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_']]\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем submission-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем пропуски\n",
    "df_ = pd.read_csv('../data/test_set.csv', dtype=dtypes, usecols=['customer_id'])\n",
    "submission = pd.DataFrame(df_['customer_id'].unique(), columns=['_ID_'])\n",
    "\n",
    "submission = submission.merge(df_test, how='left').fillna(0)\n",
    "# Пишем файл submission\n",
    "submission.to_csv('../submissions/base_1.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
