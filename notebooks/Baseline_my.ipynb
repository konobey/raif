{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Boosters] Raiffeisen Data Cup. Baseline\n",
    "Общий подход:\n",
    "- Добавляем к каждой транзакции столбец: is_work (если транзакция находится в пределах 0.02 от дома клиента)\n",
    "- Добавляем к каждой транзакции столбец: is_home (если транзакция находится в пределах 0.02 от работы клиента)\n",
    "- Обучаем классификатор предсказывающий вероятность (is_home == 1) для транзакции\n",
    "- Обучаем классификатор предсказывающий вероятность (is_work == 1) для транзакции\n",
    "\n",
    "Точность определения местоположения:\n",
    "- для классификатора is_home: ~3x%\n",
    "- для классификатора is_work: ~2x%\n",
    "- общая оценка на Public Leaderboard: ???\n",
    "\n",
    "Примечание\n",
    "* Требуется Python версии 3.5\n",
    "* Требуется библиотека xgboost (для обучения использовалась xgboost версии 0.7.post3)\n",
    "* Требуются файлы: test_set.csv, train_set.csv в одном каталоге с данным скриптом\n",
    "* Требования к памяти: должно работать с 2Гб свободного RAM\n",
    "* Время работы: ~3 минуты (тестировалось на процессоре Intel Core i7-4770)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "MODULES_PATH = '../code/'\n",
    "if MODULES_PATH not in sys.path:\n",
    "    sys.path.append(MODULES_PATH)\n",
    "import mfuncs\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_columns = 1000\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим типы колонок для экономии памяти\n",
    "dtypes = {\n",
    "    'transaction_date': str,\n",
    "    'atm_address': str,\n",
    "    'country': str,\n",
    "    'city': str,\n",
    "    'amount': np.float32,\n",
    "    'currency': np.float32,\n",
    "    'mcc': str,\n",
    "    'customer_id': str,\n",
    "    'pos_address': str,\n",
    "    'atm_address': str,\n",
    "    'pos_adress_lat': np.float32,\n",
    "    'pos_adress_lon': np.float32,\n",
    "    'pos_address_lat': np.float32,\n",
    "    'pos_address_lon': np.float32,\n",
    "    'atm_address_lat': np.float32,\n",
    "    'atm_address_lon': np.float32,\n",
    "    'home_add_lat': np.float32,\n",
    "    'home_add_lon': np.float32,\n",
    "    'work_add_lat': np.float32,\n",
    "    'work_add_lon': np.float32,\n",
    "}\n",
    "\n",
    "# для экономии памяти будем загружать только часть атрибутов транзакций\n",
    "usecols_train = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_adress_lat', 'pos_adress_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat','home_add_lon','work_add_lat','work_add_lon']\n",
    "usecols_test = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем train_set, test_set, соединяем в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'transaction_date': str,\n",
    "    'atm_address': str,\n",
    "    'country': str,\n",
    "    'city': str,\n",
    "    'amount': np.float32,\n",
    "    'currency': np.float32,\n",
    "    'mcc': str,\n",
    "    'customer_id': str,\n",
    "    'pos_address': str,\n",
    "    'atm_address': str,\n",
    "    'pos_adress_lat': np.float32,\n",
    "    'pos_adress_lon': np.float32,\n",
    "    'pos_address_lat': np.float32,\n",
    "    'pos_address_lon': np.float32,\n",
    "    'atm_address_lat': np.float32,\n",
    "    'atm_address_lon': np.float32,\n",
    "    'home_add_lat': np.float32,\n",
    "    'home_add_lon': np.float32,\n",
    "    'work_add_lat': np.float32,\n",
    "    'work_add_lon': np.float32,\n",
    "}\n",
    "\n",
    "rnm = {\n",
    "    'atm_address_lat': 'atm_lat',\n",
    "    'atm_address_lon': 'atm_lon',\n",
    "    'pos_adress_lat': 'pos_lat',\n",
    "    'pos_adress_lon': 'pos_lon',\n",
    "    'pos_address_lat': 'pos_lat',\n",
    "    'pos_address_lon': 'pos_lon',\n",
    "    'home_add_lat': 'home_lat',\n",
    "    'home_add_lon': 'home_lon',\n",
    "    'work_add_lat': 'work_lat',\n",
    "    'work_add_lon': 'work_lon',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train_set.csv', dtype=dtypes)\n",
    "df_test = pd.read_csv('../data/test_set.csv', dtype=dtypes)\n",
    "\n",
    "df_train.rename(columns=rnm, inplace=True)\n",
    "df_test.rename(columns=rnm, inplace=True)\n",
    "\n",
    "# соединяем test/train в одном DataFrame\n",
    "df_train['is_train'] = np.int32(1)\n",
    "df_test['is_train'] = np.int32(0)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "del df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обрабатываем дату транзакции и категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['currency'] = df_all['currency'].fillna(-1).astype(np.int32)\n",
    "df_all['mcc'] = df_all['mcc'].apply(lambda x: int(x.replace(',', ''))).astype(np.int32)\n",
    "df_all['city'] = df_all['city'].factorize()[0].astype(np.int32)\n",
    "df_all['country'] = df_all['country'].factorize()[0].astype(np.int32)\n",
    "\n",
    "# удаляем транзакции без даты\n",
    "df_all = df_all[~df_all['transaction_date'].isnull()]\n",
    "df_all['transaction_date'] =  pd.to_datetime(df_all['transaction_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи для даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['month'] = df_all.transaction_date.dt.month\n",
    "df_all['day'] = df_all.transaction_date.dt.day\n",
    "df_all['dayofyear'] = df_all.transaction_date.dt.dayofyear\n",
    "df_all['dayofweek'] = df_all.transaction_date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приводим адрес транзакции для pos и atm-транзакций к единообразному виду\n",
    "Просто объединяем в одну колонку и добавляем фичу - это атм или пос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['is_atm'] = (~df_all['atm_lat'].isnull()).astype(np.int8)\n",
    "df_all['is_pos'] = (~df_all['pos_lat'].isnull()).astype(np.int8)\n",
    "\n",
    "df_all['add_lat'] = df_all['atm_lat'].fillna(0) + df_all['pos_lat'].fillna(0)\n",
    "df_all['add_lon'] = df_all['atm_lon'].fillna(0) + df_all['pos_lon'].fillna(0)\n",
    "\n",
    "df_all.drop(['atm_lat','atm_lon','pos_lat','pos_lon'], axis=1, inplace=True)\n",
    "\n",
    "df_all = df_all[~((df_all['add_lon'] == 0) & (df_all['add_lon'] == 0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем признаки is_home, is_work\n",
    "TODO: удалить чуваков у которых несколько домов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = df_all['home_lat'] - df_all['add_lat']\n",
    "lon = df_all['home_lon'] - df_all['add_lon']\n",
    "\n",
    "df_all['is_home'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int8)\n",
    "df_all['has_home'] = (~df_all['home_lon'].isnull()).astype(np.int8)\n",
    "\n",
    "lat = df_all['work_lat'] - df_all['add_lat']\n",
    "lon = df_all['work_lon'] - df_all['add_lon']\n",
    "df_all['is_work'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int8)\n",
    "df_all['has_work'] = (~df_all['work_lon'].isnull()).astype(np.int8)\n",
    "\n",
    "df_all.drop(['work_lat','work_lon','home_lat','home_lon'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем категориальный признак для адреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['address'] = df_all['add_lat'].apply(lambda x: \"%.02f\" % x) + ';' + df_all['add_lon'].apply(lambda x: \"%.02f\" % x)\n",
    "df_all['address'] = df_all['address'].factorize()[0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем несколько абонентских фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество транзакций каждого клиента\n",
    "df_all = df_all.merge(df_all.groupby('customer_id')['amount'].count().reset_index(name='cid_trans_count'), how='left')\n",
    "df_all['cid_trans_count'] = df_all['cid_trans_count'].astype(np.int32)\n",
    "\n",
    "df_all = df_all.merge(df_all.groupby(['customer_id','address'])['amount'].count().reset_index(name='cid_add_trans_count'), \n",
    "                      how='left')\n",
    "df_all['cid_add_trans_count'] = df_all['cid_add_trans_count'].astype(np.int32)\n",
    "\n",
    "# какая часть транзакций клиента приходится на данный адрес\n",
    "# TODO: БОЛЬШЕ ТАКИХ ФИЧ\n",
    "df_all['ratio1'] = df_all['cid_add_trans_count'] / df_all['cid_trans_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мои фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим признаки после групбая\n",
    "df_gb = df_all.groupby('customer_id')\n",
    "coord_stat_df = df_gb[['amount', 'add_lat', 'add_lon']].agg(['mean', 'max', 'min'])\n",
    "coord_stat_df['transactions_per_user'] = df_gb.agg('size')\n",
    "coord_stat_df.columns = ['_'.join(col).strip() for col in coord_stat_df.columns.values]\n",
    "coord_stat_df.reset_index(inplace=True)\n",
    "df_all = pd.merge(df_all, coord_stat_df, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>atm_address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>currency</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>is_train</th>\n",
       "      <th>mcc</th>\n",
       "      <th>pos_address</th>\n",
       "      <th>terminal_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_atm</th>\n",
       "      <th>is_pos</th>\n",
       "      <th>add_lat</th>\n",
       "      <th>add_lon</th>\n",
       "      <th>is_home</th>\n",
       "      <th>has_home</th>\n",
       "      <th>is_work</th>\n",
       "      <th>has_work</th>\n",
       "      <th>address</th>\n",
       "      <th>cid_trans_count</th>\n",
       "      <th>cid_add_trans_count</th>\n",
       "      <th>ratio1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.884034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11606fde0c814ce78e0d726e39a0a5ee</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>196</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.844074</td>\n",
       "      <td>30.179153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.775633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e9647a5e1eacfb06713b6af755ccc595</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.844074</td>\n",
       "      <td>30.179153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.708368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5992</td>\n",
       "      <td>PR.MARSHALA ZHUKOVA,31St Petersburg190000    7...</td>\n",
       "      <td>df06c1fcd3718a514535ae822785f716</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.858200</td>\n",
       "      <td>30.229023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.787498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6c5e5793ebc984fb72875feffff62854</td>\n",
       "      <td>2017-09-09</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>252</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.844074</td>\n",
       "      <td>30.179153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.892510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0dc0137d280a2a82d2dc89282450ff1b</td>\n",
       "      <td>1</td>\n",
       "      <td>5261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0576445d74e374c92c0902e612fca356</td>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>187</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.844074</td>\n",
       "      <td>30.179153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount atm_address  city  country  currency  \\\n",
       "0  2.884034         NaN     0        0       643   \n",
       "1  2.775633         NaN     0        0       643   \n",
       "2  3.708368         NaN     1        0       643   \n",
       "3  2.787498         NaN     0        0       643   \n",
       "4  2.892510         NaN     0        0       643   \n",
       "\n",
       "                        customer_id  is_train   mcc  \\\n",
       "0  0dc0137d280a2a82d2dc89282450ff1b         1  5261   \n",
       "1  0dc0137d280a2a82d2dc89282450ff1b         1  5261   \n",
       "2  0dc0137d280a2a82d2dc89282450ff1b         1  5992   \n",
       "3  0dc0137d280a2a82d2dc89282450ff1b         1  5261   \n",
       "4  0dc0137d280a2a82d2dc89282450ff1b         1  5261   \n",
       "\n",
       "                                         pos_address  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  PR.MARSHALA ZHUKOVA,31St Petersburg190000    7...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        terminal_id transaction_date  month  day  dayofyear  \\\n",
       "0  11606fde0c814ce78e0d726e39a0a5ee       2017-07-15      7   15        196   \n",
       "1  e9647a5e1eacfb06713b6af755ccc595       2017-10-27     10   27        300   \n",
       "2  df06c1fcd3718a514535ae822785f716       2017-10-03     10    3        276   \n",
       "3  6c5e5793ebc984fb72875feffff62854       2017-09-09      9    9        252   \n",
       "4  0576445d74e374c92c0902e612fca356       2017-07-06      7    6        187   \n",
       "\n",
       "   dayofweek  is_atm  is_pos    add_lat    add_lon  is_home  has_home  \\\n",
       "0          5       0       1  59.844074  30.179153        0         1   \n",
       "1          4       0       1  59.844074  30.179153        0         1   \n",
       "2          1       0       1  59.858200  30.229023        1         1   \n",
       "3          5       0       1  59.844074  30.179153        0         1   \n",
       "4          3       0       1  59.844074  30.179153        0         1   \n",
       "\n",
       "   is_work  has_work  address  cid_trans_count  cid_add_trans_count    ratio1  \n",
       "0        1         1        0               70                   23  0.328571  \n",
       "1        1         1        0               70                   23  0.328571  \n",
       "2        0         1        1               70                   10  0.142857  \n",
       "3        1         1        0               70                   23  0.328571  \n",
       "4        1         1        0               70                   23  0.328571  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['add_lat', 'add_lon']\n",
    "types = ['min', 'max', 'mean']\n",
    "for c in cols:\n",
    "    for t in types:\n",
    "        df_all['{}_diff_{}'.format(c, t)] = np.abs(df_all[c] - df_all['{}_{}'.format(c, t)])\n",
    "df_all = pd.concat([df_all, pd.get_dummies(df_all['mcc'], prefix='mcc')], axis=1)\n",
    "del df_all['mcc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ys = ['is_home', 'is_work']\n",
    "drop_cols = ['atm_address', 'customer_id', 'pos_address', 'terminal_id', 'transaction_date', \n",
    "             'is_home' ,'has_home', 'is_work', 'has_work', 'is_train']\n",
    "\n",
    "drop_cols += ['pred:is_home', 'pred:is_work']\n",
    "y_cols = ['is_home', 'is_work']\n",
    "usecols = df_all.drop(drop_cols, 1, errors='ignore').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'metric' : 'binary_logloss',\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'num_threads': 12,\n",
    "    'verbose': 0,\n",
    "}\n",
    "\n",
    "model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[30]\tvalid_0's binary_logloss: 0.485192\n",
      "[60]\tvalid_0's binary_logloss: 0.455256\n",
      "[90]\tvalid_0's binary_logloss: 0.447628\n",
      "[120]\tvalid_0's binary_logloss: 0.446302\n",
      "[150]\tvalid_0's binary_logloss: 0.444924\n",
      "[180]\tvalid_0's binary_logloss: 0.444605\n",
      "[210]\tvalid_0's binary_logloss: 0.444621\n",
      "[240]\tvalid_0's binary_logloss: 0.44595\n",
      "[270]\tvalid_0's binary_logloss: 0.445782\n",
      "[300]\tvalid_0's binary_logloss: 0.446568\n",
      "[330]\tvalid_0's binary_logloss: 0.446897\n",
      "[360]\tvalid_0's binary_logloss: 0.446436\n",
      "[390]\tvalid_0's binary_logloss: 0.446905\n",
      "[420]\tvalid_0's binary_logloss: 0.447577\n",
      "[450]\tvalid_0's binary_logloss: 0.447769\n",
      "[480]\tvalid_0's binary_logloss: 0.448543\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.444184\n"
     ]
    }
   ],
   "source": [
    "y_col = 'is_home'\n",
    "\n",
    "cust_train = df_all[df_all['is_train']==1].groupby('customer_id')[y_col.replace('is_','has_')].max()\n",
    "cust_train = cust_train[cust_train > 0].index\n",
    "\n",
    "cust_train, cust_valid = train_test_split(cust_train, test_size=0.2, shuffle=True, random_state=111)\n",
    "\n",
    "df_train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(df_all, how='left')\n",
    "df_valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(df_all, how='left')\n",
    "\n",
    "lgb_train = lgb.Dataset(df_train[usecols], df_train[y_col])\n",
    "lgb_valid = lgb.Dataset(df_valid[usecols], df_valid[y_col])\n",
    "\n",
    "gbm_h = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets=[lgb_valid],\n",
    "                num_boost_round=2000,\n",
    "                verbose_eval=30,\n",
    "                early_stopping_rounds=300)\n",
    "\n",
    "model[y_col] = gbm_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[30]\tvalid_0's binary_logloss: 0.425004\n",
      "[60]\tvalid_0's binary_logloss: 0.386691\n",
      "[90]\tvalid_0's binary_logloss: 0.375533\n",
      "[120]\tvalid_0's binary_logloss: 0.37015\n",
      "[150]\tvalid_0's binary_logloss: 0.367881\n",
      "[180]\tvalid_0's binary_logloss: 0.366961\n",
      "[210]\tvalid_0's binary_logloss: 0.366866\n",
      "[240]\tvalid_0's binary_logloss: 0.367105\n",
      "[270]\tvalid_0's binary_logloss: 0.367206\n",
      "[300]\tvalid_0's binary_logloss: 0.368097\n",
      "[330]\tvalid_0's binary_logloss: 0.369725\n",
      "[360]\tvalid_0's binary_logloss: 0.370166\n",
      "[390]\tvalid_0's binary_logloss: 0.371453\n",
      "[420]\tvalid_0's binary_logloss: 0.372517\n",
      "[450]\tvalid_0's binary_logloss: 0.371764\n",
      "[480]\tvalid_0's binary_logloss: 0.373099\n",
      "[510]\tvalid_0's binary_logloss: 0.373394\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's binary_logloss: 0.366385\n"
     ]
    }
   ],
   "source": [
    "y_col = 'is_work'\n",
    "\n",
    "cust_train = df_all[df_all['is_train']==1].groupby('customer_id')[y_col.replace('is_','has_')].max()\n",
    "cust_train = cust_train[cust_train > 0].index\n",
    "\n",
    "cust_train, cust_valid = train_test_split(cust_train, test_size=0.2, shuffle=True, random_state=111)\n",
    "\n",
    "df_train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(df_all, how='left')\n",
    "df_valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(df_all, how='left')\n",
    "\n",
    "lgb_train = lgb.Dataset(df_train[usecols], df_train[y_col])\n",
    "lgb_valid = lgb.Dataset(df_valid[usecols], df_valid[y_col])\n",
    "\n",
    "gbm_w = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets=[lgb_valid],\n",
    "                num_boost_round=2000,\n",
    "                verbose_eval=30,\n",
    "                early_stopping_rounds=300)\n",
    "\n",
    "model[y_col] = gbm_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _best(x):\n",
    "    ret = None\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        if pred in x:\n",
    "            i = (x[pred].idxmax())\n",
    "            cols = [pred, 'add_lat', 'add_lon']\n",
    "            if col in x:\n",
    "                cols.append(col)\n",
    "            tmp = x.loc[i,cols]\n",
    "            tmp.rename({\n",
    "                'add_lat':'%s:add_lat' % col,\n",
    "                'add_lon':'%s:add_lon' % col,\n",
    "            }, inplace = True)\n",
    "            if ret is None:\n",
    "                ret = tmp\n",
    "            else:\n",
    "                ret = pd.concat([ret, tmp])\n",
    "    return ret\n",
    "\n",
    "def predict_proba(dt, ys=['is_home', 'is_work']):\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        dt[pred] = model[col].predict(dt[usecols])\n",
    "    return dt.groupby('customer_id').apply(_best).reset_index()\n",
    "\n",
    "def score(dt, ys=['is_home', 'is_work']):\n",
    "    dt_ret = predict_proba(dt, ys)\n",
    "    mean = 0.0\n",
    "    for col in ys:\n",
    "        col_mean = dt_ret[col].mean()\n",
    "        mean += col_mean\n",
    "    if len(ys) == 2:\n",
    "        mean = mean / len(ys)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.46437227338826953\n",
      "Test accuracy: 0.4728682170542636\n",
      "Train accuracy: 0.35918565196316043\n",
      "Test accuracy: 0.32945736434108525\n"
     ]
    }
   ],
   "source": [
    "print (\"Train accuracy:\", score(df_train, ys=['is_home']))\n",
    "print (\"Test accuracy:\", score(df_valid, ys=['is_home']))\n",
    "\n",
    "print (\"Train accuracy:\", score(df_train, ys=['is_work']))\n",
    "print (\"Test accuracy:\", score(df_valid, ys=['is_work']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_ID_</th>\n",
       "      <th>_WORK_LAT_</th>\n",
       "      <th>_WORK_LON_</th>\n",
       "      <th>_HOME_LAT_</th>\n",
       "      <th>_HOME_LON_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00021683ccb416637fe9a4cd35e4606e</td>\n",
       "      <td>55.027000</td>\n",
       "      <td>82.917999</td>\n",
       "      <td>55.038212</td>\n",
       "      <td>82.977364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002d0f8a642272b41c292c12ab6e602</td>\n",
       "      <td>53.199818</td>\n",
       "      <td>50.173374</td>\n",
       "      <td>53.199818</td>\n",
       "      <td>50.173374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d182d9fede3ba2534b2d5e5ad27e</td>\n",
       "      <td>43.584999</td>\n",
       "      <td>39.723999</td>\n",
       "      <td>43.586273</td>\n",
       "      <td>39.724274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0008c2445518c9392cb356c5c3db3392</td>\n",
       "      <td>51.528755</td>\n",
       "      <td>46.040150</td>\n",
       "      <td>51.529644</td>\n",
       "      <td>46.029316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000b373cc4969c0be8e0933c08da67e1</td>\n",
       "      <td>56.317917</td>\n",
       "      <td>43.925426</td>\n",
       "      <td>56.232037</td>\n",
       "      <td>43.458107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               _ID_  _WORK_LAT_  _WORK_LON_  _HOME_LAT_  \\\n",
       "0  00021683ccb416637fe9a4cd35e4606e   55.027000   82.917999   55.038212   \n",
       "1  0002d0f8a642272b41c292c12ab6e602   53.199818   50.173374   53.199818   \n",
       "2  0004d182d9fede3ba2534b2d5e5ad27e   43.584999   39.723999   43.586273   \n",
       "3  0008c2445518c9392cb356c5c3db3392   51.528755   46.040150   51.529644   \n",
       "4  000b373cc4969c0be8e0933c08da67e1   56.317917   43.925426   56.232037   \n",
       "\n",
       "   _HOME_LON_  \n",
       "0   82.977364  \n",
       "1   50.173374  \n",
       "2   39.724274  \n",
       "3   46.029316  \n",
       "4   43.458107  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_test = df_all[df_all['is_train'] == 0]['customer_id'].unique()\n",
    "df_test = pd.DataFrame(cust_test, columns = ['customer_id']).merge(df_all, how = 'left')\n",
    "df_test = predict_proba(df_test)\n",
    "df_test.rename(columns = {\n",
    "        'customer_id':'_ID_',\n",
    "        'is_home:add_lat': '_HOME_LAT_',\n",
    "        'is_home:add_lon': '_HOME_LON_',\n",
    "        'is_work:add_lat': '_WORK_LAT_',\n",
    "        'is_work:add_lon': '_WORK_LON_'}, inplace = True)\n",
    "df_test = df_test[['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_']]\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем submission-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем пропуски\n",
    "df_ = pd.read_csv('../data/test_set.csv', dtype=dtypes, usecols=['customer_id'])\n",
    "submission = pd.DataFrame(df_['customer_id'].unique(), columns=['_ID_'])\n",
    "\n",
    "submission = submission.merge(df_test, how='left').fillna(0)\n",
    "# Пишем файл submission\n",
    "submission.to_csv('../submissions/base_2_47_32.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
